{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d07c30a-1a0e-417c-a56c-ea735e971c36",
   "metadata": {},
   "source": [
    "#### TODO\n",
    "- Check how to get around article limit of 10000 if possible\n",
    "- Can use history server for other purposes?\n",
    "- What can be the advantage for using eutilities VS edirect / usecases?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dca57a6a-9835-44fb-b94e-e6c3d9d2635a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Entrez\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37344054-1aa8-4636-8fbc-b77b937e623f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_query():\n",
    "    searchterm = input(\"Enter query search term: \")\n",
    "    article_type = ('[IT] AND (\"Clinical Trial\"[PT] OR \"Randomized Controlled Trial\"[PT] OR \"Meta-Analysis\"[PT] '\n",
    "                    'OR \"Systematic Review\"[PT] OR \"Comparative Study\"[PT] OR \"Observational Study\"[PT] '\n",
    "                    'OR \"Validation Study\"[PT] OR \"Case Reports\"[PT] OR \"Review\"[PT])')\n",
    "    \n",
    "    full_query = searchterm + article_type\n",
    "    return full_query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76f8062d-5851-419b-8bbd-0b06ca44e325",
   "metadata": {},
   "outputs": [],
   "source": [
    "def history(full_query):\n",
    "    API_key = input(\"Enter API_key:\")\n",
    "\n",
    "    # Get number of data records\n",
    "    with Entrez.esearch(db=\"pubmed\", term=query, retmax=1, api_key=API_key, usehistory=\"y\") as handle:\n",
    "        results = Entrez.read(handle)\n",
    "        count = int(results[\"Count\"])\n",
    "        webenv = results[\"WebEnv\"]    \n",
    "        query_key = results[\"QueryKey\"]\n",
    "    \n",
    "    print(f\"Total articles found: {count}\")\n",
    "    print(f\"WebEnv: {webenv}, QueryKey: {query_key}\")\n",
    "    \n",
    "    return webenv, query_key, count, API_key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7748a14d-5739-46a9-9772-023856a66476",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data(webenv, query_key, count, API_key, batchsize=5000):\n",
    "    article_data = []\n",
    "    max_records = min(count, 9999)\n",
    "\n",
    "    for start in range(0, max_records, batchsize):\n",
    "        print(f\"Records {start + 1} to {min(start + batchsize, count)}...\")\n",
    "        \n",
    "        with Entrez.efetch(db=\"pubmed\", query_key=query_key, webenv=webenv, retstart=start, retmax=batchsize, \n",
    "                           rettype=\"xml\", api_key=API_key) as handle:\n",
    "            data = handle.read()\n",
    "            article_data.append(data)\n",
    "            filename = f\"pubmed_data_{start+1}_{min(start + batchsize, count)}.xml\"\n",
    "            with open(filename, 'wb') as file:\n",
    "                file.write(data)\n",
    "        \n",
    "        time.sleep(10)\n",
    "\n",
    "    print(\"Data fetching complete.\")\n",
    "    return article_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185d7ebe-6b82-4937-8f46-e0fa7c391f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import csv\n",
    "\n",
    "# Load the XML file\n",
    "tree = ET.parse('magnesium_pubmed_data.xml')  # Replace with your XML file path\n",
    "root = tree.getroot()\n",
    "\n",
    "# Prepare the CSV file\n",
    "csv_filename = 'output.csv'  # Specify the output CSV file name\n",
    "csv_columns = ['Title', 'Author', 'Journal', 'PubDate', 'DOI']  # Example columns, adjust to your XML structure\n",
    "\n",
    "# Open the CSV file in write mode\n",
    "with open(csv_filename, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=csv_columns)\n",
    "    writer.writeheader()\n",
    "\n",
    "    # Iterate through each PubMed article in the XML\n",
    "    for article in root.findall('.//PubmedArticle'):\n",
    "        # Extract relevant fields from the XML structure (adjust based on your XML structure)\n",
    "        title = article.find('.//ArticleTitle').text if article.find('.//ArticleTitle') else ''\n",
    "        author = article.find('.//AuthorList/Author/LastName').text if article.find('.//AuthorList/Author/LastName') else ''\n",
    "        journal = article.find('.//Journal/Title').text if article.find('.//Journal/Title') else ''\n",
    "        pub_date = article.find('.//PubDate/Year').text if article.find('.//PubDate/Year') else ''\n",
    "        doi = article.find('.//PubmedData/ArticleIdList/ArticleId[@IdType=\"doi\"]').text if article.find('.//PubmedData/ArticleIdList/ArticleId[@IdType=\"doi\"]') else ''\n",
    "\n",
    "        # Write the data to the CSV file\n",
    "        writer.writerow({\n",
    "            'Title': title,\n",
    "            'Author': author,\n",
    "            'Journal': journal,\n",
    "            'PubDate': pub_date,\n",
    "            'DOI': doi\n",
    "        })\n",
    "\n",
    "print(f\"Data has been written to {csv_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd2cdb2-2457-4e5d-a7ad-904be01b246e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Entrez.email = input(\"Enter emailadres:\")\n",
    "query = build_query()\n",
    "webenv, query_key, count, API_key = history(query)\n",
    "articles = fetch_data(webenv, query_key, count, API_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e377d45e-68b1-40ce-b8a2-a63950ca8ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0889a664-7aa0-49aa-aef4-983e88e9b30d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82dc901a-0eb4-4115-a2e3-41734bf60cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    To retrieve more than 10,000 UIDs from databases other than PubMed, \\n    submit multiple esearch requests while incrementing the value of retstart (see Application 3). \\n    For PubMed, ESearch can only retrieve the first 10,000 records matching the query. \\n    To obtain more than 10,000 PubMed records, consider using <EDirect> that contains additional logic\\n    to batch PubMed search results automatically so that an arbitrary number can be retrieved.\\n    For details see https://www.ncbi.nlm.nih.gov/books/NBK25499/\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    To retrieve more than 10,000 UIDs from databases other than PubMed, \n",
    "    submit multiple esearch requests while incrementing the value of retstart (see Application 3). \n",
    "    For PubMed, ESearch can only retrieve the first 10,000 records matching the query. \n",
    "    To obtain more than 10,000 PubMed records, consider using <EDirect> that contains additional logic\n",
    "    to batch PubMed search results automatically so that an arbitrary number can be retrieved.\n",
    "    For details see https://www.ncbi.nlm.nih.gov/books/NBK25499/\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
